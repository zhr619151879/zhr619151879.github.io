---
title: "[面试]-校招数据库知识"
date: 2020-12-16 11:21:54
description: "DataBase"
tags:
-
series:
- Interview
categories:
- Code

image: images/feature2/bam.png
---



## Mysql

---

##### SQL执行过程

![image-20200831221827719](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200831221827719.png)





### 事务

事务指的是满足 ACID 特性的一组操作，可以通过 Commit 提交一个事务，也可以使用 Rollback 进行回滚。



#### ACID

![image-20200818162605438](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200818162605438.png)



##### 并发一致性问题

* 丢失修改

![image-20200818162810687](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200818162810687.png)





* 读脏数据(读未提交)

读脏数据指在不同的事务下，当前事务可以读到另外事务未提交的数据。例如：T1 修改一个数据但未提交，T2 随后读取这个数据。如果 T1 撤销了这次修改，那么 T2 读取的数据是脏数据。

<img src="/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200818162920951.png" alt="image-20200818162920951" style="zoom: 33%;" />





* 不可重复度

不可重复读指在一个事务内多次读取同一数据集合。在这一事务还未结束前，另一事务也访问了该同一数据集合并做了修改，由于第二个事务的修改，第一次事务的两次读取的数据可能不一致。例如：T2 读取一个数据，T1 对该数据做了修改。如果 T2 再次读取这个数据，此时读取的结果和第一次读取的结果不同

<img src="/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200818164114168.png" alt="image-20200818164114168" style="zoom: 33%;" />





* 幻读 (侧重在读-写, 不可重复度侧重读-读)

并不是说两次读取获取的结果集不同，幻读侧重的方面是某一次的 select 操作得到的结果所表征的数据状态无法支撑后续的业务操作。更为具体一些：select 某记录是否存在，不存在，准备插入此记录，但执行 insert 时发现此记录已存在，无法插入，此时就发生了幻读。

<img src="/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200818163105069.png" alt="image-20200818163105069" style="zoom: 33%;" />





#### 四大隔离级别

* 读未提交 (Read Uncommitted)

事务中的修改，即使没有提交，对其它事务也是可见的。



* 提交读(Read Commited)

一个事务只能读取已经提交的事务所做的修改



* 可重复读 (Repeatable Read)[默认隔离级别]



> Innodb使用 MVCC解决版本读 , 使用Gap间隙锁解决当前读(for update)
>
> 为什么for update不能解决?因为锁行可以保证该行没有修改,但是不能保证没有新增删除~. 所以用gap锁(在记录之间的间隙加锁)

![image-20200820164029348](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200820164029348.png)

锁住的范围是整张表, 不可插入与删除



版本读

保证在同一个事务中多次读取同一数据的结果是一样的。

使用MVCC实现(多版本并发控制 **Multiversion concurrency control**)



![image-20200818165602216](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200818165602216.png)





* 可串行化(加行锁)

强制事务串行执行，这样多个事务互不干扰，不会出现并发一致性问题。

该隔离级别需要加锁实现，因为要使用加锁机制保证同一时间只有一个事务执行，也就是保证事务串行执行。

![image-20200818163946914](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200818163946914.png)



#### 锁类型



##### 封锁粒度



MySQL 中提供了两种封锁粒度：行级锁以及表级锁。

应该尽量只锁定需要修改的那部分数据，而不是所有的资源。锁定的数据量越少，发生锁争用的可能就越小，系统的并发程度就越高。

但是加锁需要消耗资源，锁的各种操作（包括获取锁、释放锁、以及检查锁状态）都会增加系统开销。因此封锁粒度越小，系统开销就越大。

在选择封锁粒度时，需要在锁开销和并发程度之间做一个权衡。



##### 读写锁

- 互斥锁（Exclusive），简写为 X 锁，又称写锁。
- 共享锁（Shared），简写为 S 锁，又称读锁。

规定

- 一个事务对数据对象 A 加了 X 锁，就可以对 A 进行读取和更新。加锁期间其它事务不能对 A 加任何锁。
- 一个事务对数据对象 A 加了 S 锁，可以对 A 进行读取操作，但是不能进行更新操作。加锁期间其它事务能对 A 加 S 锁，但是不能加 X 锁。

![image-20200818170037764](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200818170037764.png)



##### 意向锁



举个例子，如果表中记录1亿，事务A把其中有几条记录上了行锁了，这时事务B需要给这个表加表级锁，如果没有意向锁的话，那就要去表中查找这一亿条记录是否上锁了。如果存在意向锁，那么假如事务Ａ在更新一条记录之前，先加意向锁，再加Ｘ锁，事务B先检查该表上是否存在意向锁，存在的意向锁是否与自己准备加的锁冲突，如果有冲突，则等待直到事务Ａ释放，而无须逐条记录去检测。事务Ｂ更新表时，其实无须知道到底哪一行被锁了，它只要知道反正有一行被锁了就行了。




说白了意向锁的主要作用是处理行锁和表锁之间的矛盾，能够显示“某个事务正在某一行上持有了锁，或者准备去持有锁”



![image-20200818170925490](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200818170925490.png)

![image-20200818170937145](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200818170937145.png)

- 任意 IS/IX 锁之间都是兼容的，因为它们只表示想要对表加锁，而不是真正加锁；
- 这里兼容关系针对的是表级锁，而表级的 IX 锁和行级的 X 锁兼容，两个事务可以对两个数据行加 X 锁。（事务 T1 想要对数据行 R1 加 X 锁，事务 T2 想要对同一个表的数据行 R2 加 X 锁，两个事务都需要对该表加 IX 锁，但是 IX 锁是兼容的，并且 IX 锁与行级的 X 锁也是兼容的，因此两个事务都能加锁成功，对同一个表中的两个数据行做修改。）

（如果一个事务请求的锁模式与当前的锁兼容， InnoDB 就将请求的锁授予该事务； 反之， 如果两者不兼容，该事务就要等待锁释放。）



##### 乐观锁 悲观锁

- **乐观锁(Optimistic Lock)**：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。 乐观锁不能解决脏读的问题。

乐观锁, 顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库如果提供类似于write_condition机制的其实都是提供的乐观锁。

> 类似于 SVN、GIt 这些版本管理系统，当修改了某个文件需要提交的时候，它会检查文件的当前版本是否与服务器上的一致，如果一致那就可以直接提交，如果不一致，那就必须先更新服务器上的最新代码然后再提交（也就是先将这个文件的版本更新成和服务器一样的版本）

![image-20200818174251947](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200818174251947.png)



- **悲观锁(Pessimistic Lock)**：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。

悲观锁，顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。



![image-20200818174336392](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200818174336392.png)







##### 死锁


死锁的关键在于**：两个(**或以上)**的Session**加锁的顺序不一致。

那么对应的解决死锁问题的关键就是：让不同的session加锁有次序



死锁一般是事务相互等待对方资源，最后形成环路造成的。下面简单讲下造成相互等待最后形成环路的例子

![image-20200820155230765](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200820155230765.png)



* 死锁检测

死锁检测的原理是构建一个以事务为顶点、锁为边的有向图，判断有向图是否存在环，存在即有死锁。



* 回滚

检测到死锁之后，选择插入更新或者删除的行数最少的事务回滚，基于 INFORMATION_SCHEMA.INNODB_TRX 表中的 trx_weight 字段来判断。



### 分布式事务

#### 2PC

两阶段提交（Two-phase Commit，2PC），通过引入协调者（Coordinator）来协调参与者的行为，并最终决定这些参与者是否要真正执行事务。



* 准备阶段

协调者询问参与者事务是否执行成功，参与者发回事务执行结果。询问可以看成一种投票，需要参与者都同意才能执行。

![image-20200820172654325](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200820172654325.png)

* 提交阶段

![image-20200820172741204](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200820172741204.png)



`缺点`

![image-20200820172825232](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200820172825232.png)



#### 本地消息表

![image-20200820173305312](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200820173305312.png)



## CAP 与 BASE

### CAP

![image-20200820173417098](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200820173417098.png)

### BASE

BASE 是基本可用（Basically Available）、软状态（Soft State）和最终一致性（Eventually Consistent）三个短语的缩写。

BASE 理论是对 CAP 中一致性和可用性权衡的结果，它的核心思想是：即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。

![image-20200820173537533](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200820173537533.png)





## 索引

---

###  索引类别

Myisam和 innodb都是B+数结构.



索引是在存储引擎层实现的，而不是在服务器层实现的，所以不同存储引擎具有不同的索引类型和实现。



### B tree 

* m阶B树(m叉树)
* ![image-20200516222741370](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200516222741370.png)

> * 每个节点最多含有**m**个孩子
> * 除根和叶子、其他节点至少有**[ceil(m/2)]**个孩子
> * 根至少有2个孩子
> * 所有叶子在同一层、叶子不包含任何关键字信息
> * 对于每个非叶子：
>
> > 1）Ki 为关键字、升序排序
> >
> > 2）Pi为指向孩子的指针，其所指孩子*关键字* **小于Ki，大于K(i-1）**
> >
> > 3）关键字个数n： **[ceil(m/2)-1]<=n<=m-1**

* B 树插入： 小了合并、大了分裂 （中间元素上移）

![image-20200516220029953](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200516220029953.png)







### B+ tree

![image-20200516221509731](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200516221509731.png)

![image-20200516223121416](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200516223121416.png)



#### 对比



![image-20200516223108377](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200516223108377.png)



> (1）B+树只有叶子节点会带有指向记录的指针(带数据)，而B树则所有节点都带有。
>
> (2）B+树中所有叶子节点都是通过指针连接在一起的，而B树不会。
>
> 
>
> *B+树的优点:*
>
> (1）非叶子节点不带数据，这样一个块可以容纳更多的索引项，一是可以降低树的高度，二是一个内部节点可以定位更多的叶子节点。
> (2）叶子节点之间通过指针连接，范围扫描将十分简单。而对于B树来说，则需要在叶子节点和内部节点间不停的往返移动。
>
> 
>
> *B树的优点：*
>  对于在内部节点的数据，可直接得到，不必根据叶子节点来定位

* B树查找次数不稳定(可能叶子可能非叶子),  B+树查找稳定
* 但是两者都比红黑树IO次数好,因为层数低





##### 与红黑树的比较

![image-20200819204545590](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200819204545590.png)



### 两种引擎:

#### 存储引擎:

	* 表的类型在计算机上的存储方式



#### MyISAM

MyISAM的优势在于占用空间小，处理速度快。缺点是不支持事务的完整性和并发性。

![image-20200803112457436](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200803112457436.png)

* myi 记录索引, 叶子节点记录该键值在.myd的偏移量 frm: 表的结构
* 得到偏移量后是随机访问,速度快.



#### Innodb(支持事务处理,回滚)

* 默认引擎
* InnoDB的优势在于提供了良好的事务处理、崩溃修复能力和并发控制。`缺点是读写效率较差，占用的数据空间相对较大`。



![image-20200803112829476](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200803112829476.png)

* Innodb中，索引分叶子节点和非叶子节点，非叶子节点就像新华字典的目录，单独存放在索引段中，叶子节点则是顺序排列的





#### 比较

![image-20200812220342047](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200812220342047.png)

- 事务：InnoDB 是事务型的，可以使用 Commit 和 Rollback 语句。
- 并发：MyISAM 只支持表级锁，而 InnoDB 还支持行级锁。
- 外键：InnoDB 支持外键。
- 备份：InnoDB 支持在线热备份。
- 崩溃恢复：MyISAM 崩溃后发生损坏的概率比 InnoDB 高很多，而且恢复的速度也更慢。
- 其它特性：MyISAM 支持压缩表和空间数据索引。



#### 主键索引 非主键索引

![image-20200812224030437](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200812224030437.png)



#### 聚集索引, 非聚集索引

![image-20200819214011104](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200819214011104.png)

![image-20200819214137184](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200819214137184.png)

![image-20200812224826481](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200812224826481.png)



![image-20200812224921090](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200812224921090.png)

聚集索引适合应用于含有大量非重复值的列；使用BETWEEN,>,>=,<或<=返回一个范围值的列；被连续访问的列；返回大型结果集的查询；经常被使用连接或GROUP BY子句的查询访问的列。

非聚集索引适用于经常被分组排序的列；大数目的不同值；频繁更新的列；外键列；主键列；频繁修改索引列。



##### 为什么要使用自增主键

![image-20200819223723163](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200819223723163.png)

---

### 查询优化



Explain 用来分析 SELECT 查询语句，开发人员可以通过分析 Explain 结果来优化查询语句。

> - select_type : 查询类型，有简单查询、联合查询、子查询等
> - key : 使用的索引
> - rows : 扫描的行数

#### 优化数据访问



*减少请求的数据量*

* 只返回必要的列: 最好不要用select *

![image-20200819205429506](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200819205429506.png)

* 只返回必要的行: LIMIT来限制
* 缓存重复查询的数据: 使用缓存可以避免在数据库中进行查询，特别在要查询的数据经常被重复查询时，缓存带来的查询性能提升将会是非常明显的。



*减少服务器端扫描的行数*

* 最有效的方式是使用索引来覆盖查询。



#### 重构查询方式



* 切分大查询

一次性查询分为多次使用.



* 分解大连接查询

可以将原来的连接分解成多个单表查询，然后在用户程序中进行连接。

* 尽量不要子查询, 不要having.



#### 具体方法

* IN OR字句会使索引失效.







### 读写分离



* 主从复制

  ![image-20200819224310196](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200819224310196.png)



主服务器处理写操作以及实时性要求比较高的读操作，而从服务器处理读操作。

读写分离能提高性能的原因在于：

- 主从服务器负责各自的读和写，极大程度缓解了锁的争用；
- 从服务器可以使用 MyISAM，提升查询性能以及节约系统开销；
- 增加冗余，提高可用性。

读写分离常用代理方式来实现，代理服务器接收应用层传来的读写请求，然后决定转发到哪个服务器。

![image-20200819211511372](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200819211511372.png)



**读写分离其实只是分担了访问的压力，但是存储的压力没有解决。**





*BinLog的两种方式*



* statement: 记录所有sql修改语句, 重新执行
* row : 记录变动的行的数据.





### 切分



单库多表: 解决数据大时每次写都有表级锁的问题



#### 水平切分



**主要解决问题**：

- 单表过大造成的性能问题；
- 单表过大造成的单服务器空间问题。

![image-20200819210526051](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200819210526051.png)



可以用Merge引擎分表.

![image-20200820144744753](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200820144744753.png)

* 问题: Order By的话就都得多次~



#### 垂直切分

**主要解决问题**：

- 表与表之间资源争用问题；
- 锁争用机率小；
- 实现核心与非核心的分级存储，如UDB登陆库拆分成一级二级三级库；
- 数据库同步压力问题。
- 可以使数据行变小，一个数据页能存储更多数据，查询时减少I/O次数

![image-20200819210732296](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200819210732296.png)

* 那垂直分表影响就是之前只要一个查询的，现在需要两次查询才能拿到分表之前的完整用户表信息。



#### Sharding 策略

- 哈希取模：hash(key) % N；
- 范围：可以是 ID 范围也可以是时间范围；
- 映射表：使用单独的一个数据库来存储映射关系。





## Redis



### 概述

Redis 是速度非常快的非关系型（NoSQL）内存键值数据库，可以存储键和五种不同类型的值之间的映射。

键的类型只能为字符串，值支持五种数据类型：字符串、列表、集合、散列表、有序集合。

Redis 支持很多特性，例如将内存中的数据持久化到硬盘中，使用复制来扩展读性能，使用分片来扩展写性能。

![image-20200819225403071](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200819225403071.png)



### 数据结构



#### DICT

* 拉链法解决冲突

![image-20200820101620129](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200820101620129.png)

![image-20200820103429535](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200820103429535.png)



#### 跳表

https://www.jianshu.com/p/61f8cad04177

应用在有序集合 (ZSET)

跳跃表支持平均 O(\log N) 最坏 O(N) 复杂度的节点查找

> ​		1、由很多层结构组成；
>
> 　　2、每一层都是一个有序的链表，排列顺序为由高层到底层，都至少包含两个链表节点，分别是前面的head节点和后面的nil节点；
>
> 　　3、最底层的链表包含了所有的元素；
>
> 　　4、如果一个元素出现在某一层的链表中，那么在该层之下的链表也全都会出现（上一层的元素是当前层的元素的子集）；
>
> 　　5、链表中的每个节点都包含两个指针，一个指向同一层的下一个链表节点，另一个指向下一层的同一个链表节点；

![image-20200819233001612](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200819233001612.png)

- 插入速度非常快速，因为不需要进行旋转等操作来维护平衡性；
- 更容易实现；
- 支持无锁操作。

> ​	①、搜索：从最高层的链表节点开始，如果比当前节点要大和比当前层的下一个节点要小，那么则往下找，也就是和当前层的下一层的节点的下一个节点进行比较，以此类推，一直找到最底层的最后一个节点，如果找到则返回，反之则返回空。
>
> 　　②、插入：首先确定插入的层数，有一种方法是假设抛一枚硬币，如果是正面就累加，直到遇见反面为止，最后记录正面的次数作为插入的层数。当确定插入的层数k后，则需要将新元素插入到从底层到k层。
>
> `do( 插入层数+=1)while random() > 0.5`
>
> 　　③、删除：在各个层中找到包含指定值的节点，然后将节点从链表中删除即可，如果删除以后只剩下头尾两个节点，则删除这一层。

![image-20200820114054430](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200820114054430.png)

![image-20200820112118645](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200820112118645.png)

如上,当节点数>128或节点值大于某一个长度, 则转换成跳表(原来是字节数组)



### 持久化

 

https://baijiahao.baidu.com/s?id=1654694618189745916&wfr=spider&for=pc

##### RDB

> 将某个时间点的所有数据都存放到硬盘上。
>
> 可以将快照复制到其他服务器从而创建具有相同数据的服务器副本。
>
> 如果系统发生故障，将会丢失最后一次创建快照之后的数据。
>
> 如果数据量大，保存快照的时间会很长

##### AOF

![image-20200812231937382](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200812231937382.png)



###  主从复制

![image-20200812232013362](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200812232013362.png)



#### Sentinel

Sentinel（哨兵）可以监听集群中的服务器，并在主服务器进入下线状态时，自动从从服务器中选举出新的主服务器。







### 缓存问题



#### 缓存穿透

指的是对某个一定不存在的数据进行请求，该请求将会穿透缓存到达数据库。

解决方案：

- 对这些不存在的数据缓存一个空数据；
- 对这类请求进行过滤。

#### 缓存雪崩

指的是由于数据没有被加载到缓存中，或者缓存数据在同一时间大面积失效（过期），又或者缓存服务器宕机，导致大量的请求都到达数据库。

在有缓存的系统中，系统非常依赖于缓存，缓存分担了很大一部分的数据请求。当发生缓存雪崩时，数据库无法处理这么大的请求，导致数据库崩溃。

解决方案：

- 为了防止缓存在同一时间大面积过期导致的缓存雪崩，可以通过观察用户行为，合理设置缓存过期时间来实现；
- 为了防止缓存服务器宕机出现的缓存雪崩，可以使用分布式缓存，分布式缓存中每一个节点只缓存部分的数据，当某个节点宕机时可以保证其它节点的缓存仍然可用。
- 也可以进行缓存预热，避免在系统刚启动不久由于还未将大量数据进行缓存而导致缓存雪崩。







### 分布式锁



* setnx

![image-20200831215724759](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200831215724759.png)



* Redisson 组件. 使用lua脚本实现原子性





### Redis缓存与数据库同步方案



* 延时双删



1）先删除缓存

2）再写数据库

3）休眠500毫秒

4）再次删除缓存



* binlog异步刷新





* MQ串行化

问题就来自于“读数据库” + “写缓存” 之间的交错并发，那怎么来避免呢？
有一个方法就是：串行化，我们利用MQ将所有“读数据库” + “写缓存”的步骤串行化

![image-20200831222849522](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200831222849522.png)





#### Redis内存淘汰策略



##### 过期策略



* 定期删除

![image-20200913182936522](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200913182936522.png)





* 惰性删除

![image-20200913183007954](/Users/zhuhaoran/Library/Application Support/typora-user-images/image-20200913183007954.png)





* why淘汰策略:

因为不管是定期采样删除还是惰性删除都不是一种完全精准的删除，就还是会存在key没有被删除掉的场景，所以就需要内存淘汰策略进行补充。





##### 内存淘汰策略



Redis的内存淘汰策略是指在Redis的用于缓存的内存不足时，怎么处理需要新写入且需要申请额外空间的数据。



**Redis的LRU实现**



Redis维护了一个24位时钟，可以简单理解为当前系统的时间戳，每隔一定时间会更新这个时钟。每个key对象内部同样维护了一个24位的时钟，当新增key对象的时候会把系统的时钟赋值到这个内部对象时钟。比如我现在要进行LRU，那么首先拿到当前的全局时钟，然后再找到内部时钟与全局时钟距离时间最久的（差最大）进行淘汰，这里值得注意的是全局时钟只有24位，按秒为单位来表示才能存储194天，所以可能会出现key的时钟大于全局时钟的情况，如果这种情况出现那么就两个相加而不是相减来求最久的key。